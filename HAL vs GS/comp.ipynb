{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (2.38.552522) detected in PATH at C:\\Users\\ikram\\anaconda3\\Library\\bin\\chromedriver.exe might not be compatible with the detected chrome version (131.0.6778.139); currently, chromedriver 131.0.6778.108 is recommended for chrome 131.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    },
    {
     "ename": "SessionNotCreatedException",
     "evalue": "Message: session not created exception: Missing or invalid capabilities\n  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.22631 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 197\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Appel de la fonction principale\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 197\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[1], line 191\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m    190\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fonction principale pour appeler les fonctions de scraping et de comparaison.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     scrape_HAL()\n\u001b[0;32m    192\u001b[0m     scrape_Google_Scholar()\n\u001b[0;32m    193\u001b[0m     compare_json_titles(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlavien VERNIER_HAL.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m, in \u001b[0;36mscrape_HAL\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m chrome_options \u001b[38;5;241m=\u001b[39m Options()\n\u001b[0;32m     26\u001b[0m chrome_options\u001b[38;5;241m.\u001b[39madd_experimental_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetach\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 27\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(options\u001b[38;5;241m=\u001b[39mchrome_options)\n\u001b[0;32m     28\u001b[0m driver\u001b[38;5;241m.\u001b[39mmaximize_window()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mListeEnseignant.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\ikram\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[0;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     46\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mDesiredCapabilities\u001b[38;5;241m.\u001b[39mCHROME[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     47\u001b[0m     vendor_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoog\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m     49\u001b[0m     service\u001b[38;5;241m=\u001b[39mservice,\n\u001b[0;32m     50\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[0;32m     51\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ikram\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:61\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     52\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChromiumRemoteConnection(\n\u001b[0;32m     53\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[0;32m     54\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[0;32m     58\u001b[0m )\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(command_executor\u001b[38;5;241m=\u001b[39mexecutor, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[1;32mc:\\Users\\ikram\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:208\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, command_executor, keep_alive, file_detector, options)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authenticator_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_client()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_session(capabilities)\n",
      "File \u001b[1;32mc:\\Users\\ikram\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:292\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[1;34m(self, capabilities)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new session with the desired capabilities.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \n\u001b[0;32m    287\u001b[0m \u001b[38;5;124;03m:Args:\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m - capabilities - a capabilities dict to start the session with.\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    291\u001b[0m caps \u001b[38;5;241m=\u001b[39m _create_caps(capabilities)\n\u001b[1;32m--> 292\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mNEW_SESSION, caps)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaps \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ikram\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\ikram\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m: Message: session not created exception: Missing or invalid capabilities\n  (Driver info: chromedriver=2.38.552522 (437e6fbedfa8762dec75e2c5b3ddb86763dc9dcb),platform=Windows NT 10.0.22631 x86_64)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import unicodedata\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "def normalize_text(input_text):\n",
    "    \"\"\"Normaliser le texte en ASCII et en minuscules.\"\"\"\n",
    "    text = unicodedata.normalize('NFKD', input_text).encode('ascii', 'ignore').decode('utf-8')\n",
    "    text = re.sub(r'\\s*-\\s*', '-', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "    return text\n",
    "\n",
    "def random_sleep(min_time=1, max_time=3):\n",
    "    \"\"\"Fonction pour dormir un temps aléatoire entre min_time et max_time secondes.\"\"\"\n",
    "    time.sleep(random.randint(min_time, max_time))\n",
    "\n",
    "def scrape_HAL():\n",
    "    \"\"\"Fonction pour le scraping du site HAL.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_experimental_option(\"detach\", True)\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    with open(\"ListeEnseignant.txt\", \"r\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # Séparer le nom de l'enseignant et le titre\n",
    "            parts = line.strip().split(', ')\n",
    "            if len(parts) != 2:\n",
    "                print(f\"Ignorer la ligne mal formatée : {line.strip()}\")\n",
    "                continue\n",
    "            name, title = parts\n",
    "\n",
    "            # Préparer le nom de l'enseignant pour la recherche sur HAL\n",
    "            search_name = '+'.join(name.split())\n",
    "\n",
    "            # Ouvrir un fichier JSON pour enregistrer les résultats pour chaque enseignant\n",
    "            with open(f\"{name}_HAL.json\", \"w\", encoding='utf-8') as json_file:\n",
    "                results = []\n",
    "\n",
    "                # Recherche sur HAL pour chaque page de résultats\n",
    "                for i in range(1, 6):\n",
    "                    # Construire l'URL avec le nom de l'enseignant en cours\n",
    "                    url = f\"https://hal.science/search/index/?q={search_name}&rows=30&page={i}\"\n",
    "\n",
    "                    driver.get(url)\n",
    "                    time.sleep(random.uniform(5, 10))\n",
    "                    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                    error_content = soup.find('div', class_='error-content')\n",
    "                    if error_content and \"Pas de résultat\" in error_content.text:\n",
    "                        break\n",
    "\n",
    "                    items = soup.select('.pl-4.pl-sm-0')\n",
    "\n",
    "                    for item in items:\n",
    "                        result = {}\n",
    "                        result['titre'] = item.select_one('.title-results').text.strip().lower()\n",
    "                        result['auteur'] = name\n",
    "                        authors = [author.text.strip() for author in item.select('.authors-results a')]\n",
    "                        result['contributeurs'] = [author for author in authors if author != name]\n",
    "                        result['lieu de publication'] = item.select_one('.citation-results').text.strip().lower()\n",
    "                        results.append(result)\n",
    "\n",
    "                if not results:\n",
    "                    no_result = {\"auteur\": name, \"message\": \"Pas de résultat pour cet enseignant\"}\n",
    "                    json.dump(no_result, json_file, ensure_ascii=False, indent=4)\n",
    "                else:\n",
    "                    json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "def scrape_Google_Scholar(urls_file='links.txt'):\n",
    "    \"\"\"Fonction pour le scraping du site Google Scholar.\"\"\"\n",
    "    def read_urls_from_file(file_path):\n",
    "        \"\"\"Lire les URLs stockées dans un fichier texte.\"\"\"\n",
    "        with open(file_path, 'r') as file:\n",
    "            urls = file.read().splitlines()\n",
    "        return urls\n",
    "\n",
    "    def get_article_links(urls):\n",
    "        \"\"\"Extraire les liens des articles à partir d'une liste d'URLs de pages de profil Google Scholar.\"\"\"\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_experimental_option(\"detach\", True)\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        all_articles_links = []\n",
    "\n",
    "        for url in urls:\n",
    "            driver.get(url)\n",
    "            random_sleep()\n",
    "            while True:\n",
    "                try:\n",
    "                    more_button = driver.find_element(By.ID, \"gsc_bpf_more\")\n",
    "                    if not more_button.is_enabled():\n",
    "                        break\n",
    "                    more_button.click()\n",
    "                    random_sleep()\n",
    "                except Exception as e:\n",
    "                    print(\"Erreur lors du clic sur Plus : \", e)\n",
    "                    break\n",
    "                \n",
    "            articles = driver.find_elements(By.XPATH, '//*[@id=\"gsc_a_b\"]/tr/td[1]/a')\n",
    "            for article in articles:\n",
    "                all_articles_links.append(article.get_attribute('href'))\n",
    "            random_sleep()\n",
    "\n",
    "        driver.quit()\n",
    "        return all_articles_links\n",
    "\n",
    "    def scrap_articles(articles_links):\n",
    "        \"\"\"Scrapper les détails des articles en utilisant les liens récupérés.\"\"\"\n",
    "        driver = webdriver.Chrome()\n",
    "        articles_data = []\n",
    "        \n",
    "        for article_url in articles_links:\n",
    "            driver.get(article_url)\n",
    "            random_sleep()\n",
    "            article_data = {\n",
    "                'titre article': find_text(driver, '//*[@id=\"gsc_oci_title\"]/a'),\n",
    "                'Contributeurs': find_text(driver, '//*[@id=\"gsc_oci_table\"]/div[1]/div[2]'),\n",
    "                'Date de publication': find_text(driver, '//*[@id=\"gsc_oci_table\"]/div[2]/div[2]'),\n",
    "                'Type de publication': find_text(driver, '//*[@id=\"gsc_oci_table\"]/div[3]/div[1]'),\n",
    "                'Lieu': find_text(driver, '//*[@id=\"gsc_oci_table\"]/div[3]/div[2]'),\n",
    "                'Description': find_text(driver, '//*[@id=\"gsc_oci_descr\"]/div')\n",
    "            }\n",
    "            articles_data.append(article_data)\n",
    "        \n",
    "        driver.quit()\n",
    "        return articles_data\n",
    "\n",
    "    def find_text(driver, xpath):\n",
    "        \"\"\"Tenter de trouver et retourner le texte à partir d'un élément spécifié par XPath.\"\"\"\n",
    "        try:\n",
    "            return driver.find_element(By.XPATH, xpath).text.strip().lower()\n",
    "        except:\n",
    "            return \"\"\n",
    "\n",
    "    def save_to_json(articles_data, filename='articles.json'):\n",
    "        \"\"\"Sauvegarder les données des articles dans un fichier JSON.\"\"\"\n",
    "        with open(filename, 'w', encoding='UTF-8') as json_file:\n",
    "            json.dump(articles_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    urls = read_urls_from_file(urls_file)\n",
    "    articles_links = get_article_links(urls)\n",
    "    articles_data = scrap_articles(articles_links)\n",
    "    save_to_json(articles_data)\n",
    "\n",
    "def compare_titles_with_tolerance(titles1, titles2, tolerance=3):\n",
    "    \"\"\"Comparer les titres avec une tolérance donnée.\"\"\"\n",
    "    matched_titles = set()\n",
    "    for title1 in titles1:\n",
    "        for title2 in titles2:\n",
    "            if levenshtein_distance(title1, title2) <= tolerance:\n",
    "                matched_titles.add((title1, title2))\n",
    "    return matched_titles\n",
    "\n",
    "def compare_json_titles(file1, file2):\n",
    "    \"\"\"Comparer les titres de deux fichiers JSON.\"\"\"\n",
    "    with open(file1, 'r', encoding='utf-8') as f1, open(file2, 'r', encoding='utf-8') as f2:\n",
    "        data1 = json.load(f1)\n",
    "        data2 = json.load(f2)\n",
    "\n",
    "    titles1 = {normalize_text(article['titre']) for article in data1}\n",
    "    titles2 = {normalize_text(article['titre article']) for article in data2}\n",
    "\n",
    "    # Find matching titles considering the tolerance\n",
    "    matched_titles = compare_titles_with_tolerance(titles1, titles2)\n",
    "\n",
    "    # Finding unmatched titles\n",
    "    unmatched_titles1 = titles1 - {title1 for title1, title2 in matched_titles}\n",
    "    unmatched_titles2 = titles2 - {title2 for title1, title2 in matched_titles}\n",
    "\n",
    "    results = {\n",
    "        'matched_titles': list(matched_titles),\n",
    "        'missing_in_file1': list(unmatched_titles1),\n",
    "        'missing_in_file2': list(unmatched_titles2)\n",
    "    }\n",
    "\n",
    "    with open('comparison_results.json', 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(results, outfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fonction principale pour appeler les fonctions de scraping et de comparaison.\"\"\"\n",
    "    scrape_HAL()\n",
    "    scrape_Google_Scholar()\n",
    "    compare_json_titles(\"Flavien VERNIER_HAL.json\", \"articles.json\")\n",
    "\n",
    "# Appel de la fonction principale\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
